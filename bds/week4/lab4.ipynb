{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>barthel</th>\n",
       "      <th>charlson</th>\n",
       "      <th>codidiagingreso</th>\n",
       "      <th>codservicioreal</th>\n",
       "      <th>creatinina</th>\n",
       "      <th>drg</th>\n",
       "      <th>estancias</th>\n",
       "      <th>glucosa</th>\n",
       "      <th>hematocrito</th>\n",
       "      <th>...</th>\n",
       "      <th>metastatic_tumor</th>\n",
       "      <th>num_grupoact3_HOSP</th>\n",
       "      <th>numurgenciasprevias</th>\n",
       "      <th>potasio</th>\n",
       "      <th>proteina_c_reactiva</th>\n",
       "      <th>rdw_cv</th>\n",
       "      <th>rdw_sd</th>\n",
       "      <th>sodio</th>\n",
       "      <th>urea</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HNEM</td>\n",
       "      <td>0.42</td>\n",
       "      <td>141.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>29.548684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.653334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.9</td>\n",
       "      <td>83.1</td>\n",
       "      <td>145.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HNEF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>444.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.648684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.8</td>\n",
       "      <td>46.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>M97303</td>\n",
       "      <td>HHEM</td>\n",
       "      <td>0.92</td>\n",
       "      <td>691.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.848684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.153334</td>\n",
       "      <td>1.090658</td>\n",
       "      <td>23.1</td>\n",
       "      <td>57.2</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  barthel  charlson codidiagingreso codservicioreal  creatinina    drg   \n",
       "0   80      NaN       4.0             NaN            HNEM        0.42  141.0  \\\n",
       "1   67      NaN       5.0             NaN            HNEF         NaN  444.0   \n",
       "2   75      NaN      13.0          M97303            HHEM        0.92  691.0   \n",
       "\n",
       "   estancias  glucosa  hematocrito  ...  metastatic_tumor  num_grupoact3_HOSP   \n",
       "0        7.0    110.0    29.548684  ...               0.0                 NaN  \\\n",
       "1       11.0      NaN    30.648684  ...               0.0                 NaN   \n",
       "2       14.0      NaN    33.848684  ...               0.0                 NaN   \n",
       "\n",
       "   numurgenciasprevias   potasio  proteina_c_reactiva  rdw_cv  rdw_sd  sodio   \n",
       "0                  6.0  4.653334                  NaN    24.9    83.1  145.0  \\\n",
       "1                  1.0       NaN                  NaN    14.8    46.3    NaN   \n",
       "2                 16.0  5.153334             1.090658    23.1    57.2  135.0   \n",
       "\n",
       "   urea  label  \n",
       "0   NaN    0.0  \n",
       "1   NaN    0.0  \n",
       "2   NaN    0.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('inadvance_synth.csv', sep=';', index_col=0)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38416, 21)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. What is the size of the dataframe?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.4033215326947"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. What is the mean age?\n",
    "df['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.361737254115944"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. What is the age standard deviation (std)?\n",
    "df['age'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "barthel                28198\n",
       "num_grupoact3_HOSP     21001\n",
       "proteina_c_reactiva    18175\n",
       "urea                   14260\n",
       "codidiagingreso        11378\n",
       "glucosa                 9228\n",
       "potasio                 8646\n",
       "rdw_sd                  8334\n",
       "rdw_cv                  8334\n",
       "hematocrito             8302\n",
       "leucocitos              8302\n",
       "sodio                   8142\n",
       "creatinina              7951\n",
       "drg                     3640\n",
       "numurgenciasprevias      552\n",
       "metastatic_tumor          77\n",
       "charlson                  77\n",
       "age                        0\n",
       "estancias                  0\n",
       "codservicioreal            0\n",
       "label                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Which is the variable with the most amount of missing values? Can you list the name of the variables,\n",
    "# sorting them by number of missing values?\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codidiagingreso    object\n",
       "codservicioreal    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Name which are the categorical variables.\n",
    "df.dtypes[df.dtypes == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0.0    24985\n",
       "1.0    13431\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Extract the ‘label’ column to another variable. How many positive cases there are? And negatives?\n",
    "label = df['label']\n",
    "label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#▪ Split the dataset in two: train (80%) and test (20%). Use a seed to allow replication.\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "y_train = train[\"label\"]\n",
    "train.drop(\"label\", axis=1, inplace=True)\n",
    "y_test = test[\"label\"]\n",
    "test.drop(\"label\", axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30732,), (30732, 20), (7684,), (7684, 20))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, train.shape, y_test.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "codidiagingreso\n",
       "401.9     2734\n",
       "518.81     643\n",
       "486        533\n",
       "250.00     532\n",
       "414.9      511\n",
       "          ... \n",
       "376.11       1\n",
       "281.2        1\n",
       "453.6        1\n",
       "482.49       1\n",
       "147.1        1\n",
       "Name: count, Length: 2038, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_num_col = df.select_dtypes(exclude=['number']).columns.tolist()\n",
    "# df[non_num_col[-1]].value_counts()\n",
    "df[non_num_col[0]].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30732, 20)\n",
      "(7684, 20)\n"
     ]
    }
   ],
   "source": [
    "# 1. How many samples have each set after the split?\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['codidiagingreso', 'codservicioreal']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes[df.dtypes == 'object'].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tu jest bład "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_encoded_df=       codidiagingreso_003.0  codidiagingreso_003.1  codidiagingreso_005.3   \n",
      "0                        0.0                    0.0                    0.0  \\\n",
      "1                        0.0                    0.0                    0.0   \n",
      "2                        0.0                    0.0                    0.0   \n",
      "3                        0.0                    0.0                    0.0   \n",
      "4                        0.0                    0.0                    0.0   \n",
      "...                      ...                    ...                    ...   \n",
      "30727                    0.0                    0.0                    0.0   \n",
      "30728                    0.0                    0.0                    0.0   \n",
      "30729                    0.0                    0.0                    0.0   \n",
      "30730                    0.0                    0.0                    0.0   \n",
      "30731                    0.0                    0.0                    0.0   \n",
      "\n",
      "       codidiagingreso_007.8  codidiagingreso_008.43  codidiagingreso_008.45   \n",
      "0                        0.0                     0.0                     0.0  \\\n",
      "1                        0.0                     0.0                     0.0   \n",
      "2                        0.0                     0.0                     0.0   \n",
      "3                        0.0                     0.0                     0.0   \n",
      "4                        0.0                     0.0                     0.0   \n",
      "...                      ...                     ...                     ...   \n",
      "30727                    0.0                     0.0                     0.0   \n",
      "30728                    0.0                     0.0                     0.0   \n",
      "30729                    0.0                     0.0                     0.0   \n",
      "30730                    0.0                     0.0                     0.0   \n",
      "30731                    0.0                     0.0                     0.0   \n",
      "\n",
      "       codidiagingreso_008.46  codidiagingreso_008.47  codidiagingreso_008.49   \n",
      "0                         0.0                     0.0                     0.0  \\\n",
      "1                         0.0                     0.0                     0.0   \n",
      "2                         0.0                     0.0                     0.0   \n",
      "3                         0.0                     0.0                     0.0   \n",
      "4                         0.0                     0.0                     0.0   \n",
      "...                       ...                     ...                     ...   \n",
      "30727                     0.0                     0.0                     0.0   \n",
      "30728                     0.0                     0.0                     0.0   \n",
      "30729                     0.0                     0.0                     0.0   \n",
      "30730                     0.0                     0.0                     0.0   \n",
      "30731                     0.0                     0.0                     0.0   \n",
      "\n",
      "       codidiagingreso_009.0  ...  codservicioreal_HUEI  codservicioreal_HUEM   \n",
      "0                        0.0  ...                   0.0                   0.0  \\\n",
      "1                        0.0  ...                   0.0                   0.0   \n",
      "2                        0.0  ...                   0.0                   0.0   \n",
      "3                        0.0  ...                   0.0                   0.0   \n",
      "4                        0.0  ...                   0.0                   0.0   \n",
      "...                      ...  ...                   ...                   ...   \n",
      "30727                    0.0  ...                   0.0                   0.0   \n",
      "30728                    0.0  ...                   0.0                   0.0   \n",
      "30729                    0.0  ...                   0.0                   0.0   \n",
      "30730                    0.0  ...                   0.0                   0.0   \n",
      "30731                    0.0  ...                   0.0                   0.0   \n",
      "\n",
      "       codservicioreal_HUHP  codservicioreal_HULM  codservicioreal_HUMI   \n",
      "0                       0.0                   0.0                   0.0  \\\n",
      "1                       0.0                   0.0                   0.0   \n",
      "2                       0.0                   0.0                   0.0   \n",
      "3                       0.0                   0.0                   0.0   \n",
      "4                       0.0                   0.0                   0.0   \n",
      "...                     ...                   ...                   ...   \n",
      "30727                   0.0                   0.0                   0.0   \n",
      "30728                   0.0                   0.0                   0.0   \n",
      "30729                   0.0                   0.0                   0.0   \n",
      "30730                   0.0                   0.0                   0.0   \n",
      "30731                   0.0                   0.0                   0.0   \n",
      "\n",
      "       codservicioreal_HUML  codservicioreal_HUMM  codservicioreal_HURO   \n",
      "0                       0.0                   0.0                   0.0  \\\n",
      "1                       0.0                   0.0                   0.0   \n",
      "2                       0.0                   0.0                   0.0   \n",
      "3                       0.0                   0.0                   0.0   \n",
      "4                       0.0                   0.0                   0.0   \n",
      "...                     ...                   ...                   ...   \n",
      "30727                   0.0                   0.0                   0.0   \n",
      "30728                   0.0                   0.0                   0.0   \n",
      "30729                   0.0                   0.0                   0.0   \n",
      "30730                   0.0                   0.0                   0.0   \n",
      "30731                   0.0                   0.0                   0.0   \n",
      "\n",
      "       codservicioreal_HURQ  codservicioreal_HUTP  \n",
      "0                       0.0                   0.0  \n",
      "1                       0.0                   0.0  \n",
      "2                       0.0                   0.0  \n",
      "3                       0.0                   0.0  \n",
      "4                       0.0                   0.0  \n",
      "...                     ...                   ...  \n",
      "30727                   0.0                   0.0  \n",
      "30728                   0.0                   0.0  \n",
      "30729                   0.0                   0.0  \n",
      "30730                   0.0                   0.0  \n",
      "30731                   0.0                   0.0  \n",
      "\n",
      "[30732 rows x 1925 columns]\n",
      "train=       age  barthel  charlson codidiagingreso codservicioreal  creatinina   \n",
      "29147   65      NaN       1.0           780.2            HCAR        0.76  \\\n",
      "10512   67      NaN       1.0             NaN            HNEM        0.86   \n",
      "32039   94      NaN       9.0           585.9            HMUR        0.80   \n",
      "17925   83     95.0       3.0           428.1            HCAR        1.28   \n",
      "16317   81      NaN       2.0           558.9            HMUR        0.58   \n",
      "...    ...      ...       ...             ...             ...         ...   \n",
      "6265    65      NaN       4.0           041.6            HNEM        0.91   \n",
      "11284   80     30.0      11.0             NaN            HMIN        1.53   \n",
      "38158   75      NaN       3.0           599.0            HMUR        0.61   \n",
      "860     89      0.0       9.0             NaN            HMIN        0.46   \n",
      "15795   90      NaN       1.0          807.04            HCTO         NaN   \n",
      "\n",
      "         drg  estancias  glucosa  hematocrito  leucocitos  metastatic_tumor   \n",
      "29147  171.0        4.0     91.0    38.148684        2.64               0.0  \\\n",
      "10512  139.0        5.0    150.6    41.548684       11.66               0.0   \n",
      "32039  425.0        4.0     73.7    30.948684        6.45               0.0   \n",
      "17925  198.0        3.0     96.0    35.710714        9.63               0.0   \n",
      "16317  249.0        3.0     79.9    42.548684        6.51               0.0   \n",
      "...      ...        ...      ...          ...         ...               ...   \n",
      "6265   724.0       13.0    182.0    34.148684        5.43               0.0   \n",
      "11284  194.0        6.0    141.4    27.410714        2.34               0.0   \n",
      "38158  463.0       10.0    101.0    37.848684        7.91               0.0   \n",
      "860    133.0        6.0    120.4    32.810714       12.41               0.0   \n",
      "15795    NaN        1.0      NaN          NaN         NaN               0.0   \n",
      "\n",
      "       num_grupoact3_HOSP  numurgenciasprevias   potasio  proteina_c_reactiva   \n",
      "29147                 NaN                  1.0  4.353334                  NaN  \\\n",
      "10512                 3.0                  1.0  4.563334            53.980658   \n",
      "32039                 NaN                  2.0  4.483334                  NaN   \n",
      "17925                 NaN                  7.0  4.700000                  NaN   \n",
      "16317                 NaN                  1.0  3.023334             6.360658   \n",
      "...                   ...                  ...       ...                  ...   \n",
      "6265                  NaN                  4.0  4.633334                  NaN   \n",
      "11284                13.0                 12.0  4.890000                  NaN   \n",
      "38158                 NaN                  6.0  3.483334            13.030658   \n",
      "860                   NaN                  5.0  4.410000             3.477684   \n",
      "15795                 NaN                  1.0       NaN                  NaN   \n",
      "\n",
      "         rdw_cv     rdw_sd       sodio        urea  \n",
      "29147  12.80000  38.500000  140.000000   25.352822  \n",
      "10512  14.90000  47.700000  139.000000   33.652822  \n",
      "32039  14.90000  46.800000  137.000000   30.852822  \n",
      "17925  14.56075  50.123099  138.340418   65.253918  \n",
      "16317  19.50000  52.300000  144.000000   23.652822  \n",
      "...         ...        ...         ...         ...  \n",
      "6265   15.90000  47.200000  139.000000  134.452822  \n",
      "11284  20.56075  63.623099  138.340418  146.953918  \n",
      "38158  14.90000  48.200000  142.000000   23.852822  \n",
      "860    15.96075  51.623099  139.340418   79.453918  \n",
      "15795       NaN        NaN         NaN         NaN  \n",
      "\n",
      "[30732 rows x 20 columns]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mJądro Kernel uległo awarii podczas wykonywania kodu w bieżącej komórce lub w poprzedniej komórce. Przejrzyj kod w komórkach, aby zidentyfikować możliwą przyczynę awarii. Kliknij <a href='https://aka.ms/vscodeJupyterKernelCrash'>tutaj</a>, aby uzyskać więcej informacji. W celu uzyskania dalszych szczegółów, wyświetl <a href='command:jupyter.viewOutput'>log</a> Jupyter."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_cols_train = train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "train_encoded = encoder.fit_transform(train[categorical_cols_train]).toarray()\n",
    "# print(f'{train_encoded.shape=}')\n",
    "test_encoded = encoder.transform(test[categorical_cols_train]).toarray()\n",
    "\n",
    "train_encoded_df = pd.DataFrame(train_encoded, columns=encoder.get_feature_names_out(categorical_cols_train))\n",
    "test_encoded_df = pd.DataFrame(test_encoded, columns=encoder.get_feature_names_out(categorical_cols_train))\n",
    "\n",
    "#TU JEST błąd \n",
    "print(f'{train_encoded_df.shape=}')\n",
    "print(f'{train.shape=}')\n",
    "train_df_encoded = pd.concat([train, train_encoded_df], axis=1, ignore_index=True)\n",
    "print(f'{train_df_encoded.shape=}')\n",
    "test_df_encoded = pd.concat([test, test_encoded_df], axis=1, ignore_index=True)\n",
    "\n",
    "train_df_encoded.drop(categorical_cols_train, axis=1, inplace=True)\n",
    "test_df_encoded.drop(categorical_cols_train, axis=1, inplace=True)\n",
    "print(f'{train_df_encoded.shape=}')\n",
    "\n",
    "train_df_encoded.shape\n",
    "# 30732"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the method to deal with categorical variables. Briefly explain the chosen alternative. What\n",
    "would happen if a variable in the test set contains a category that doesn’t exist on the train set? How\n",
    "would you deal with this situation?\n",
    "\n",
    "- Label Encoding involves converting each category into a unique numerical value. For example, if a categorical variable has three categories: 'A', 'B', and 'C', Label Encoding might convert them to 0, 1, and 2 respectively. If a new category is encountered in the test set that was not present in the training set, Label Encoding would still assign a unique numerical value to that category. However, this approach might not be ideal because it implies an ordinal relationship between categories which might not exist.\n",
    "- One-Hot Encoding creates binary columns for each category and indicates the presence of the category with a 1 or 0. For example, the categories 'Red', 'Green', and 'Blue' would be transformed into three columns: 'Is_Red', 'Is_Green', and 'Is_Blue. If a new category appears in the test set, it would result in a column of all zeros in the one-hot encoded representation\n",
    "- Binary Encoding first converts categories into numerical values using Label Encoding and then those numerical values are converted into binary code. The binary values are split into separate columns. For example, the numerical value 2 (binary: 010) would result in columns 'Is_0', 'Is_1', and 'Is_0'.Similar to One-Hot Encoding, if a new category appears in the test set, it would result in columns of zeros\n",
    "\n",
    "\n",
    "Yes i did, thats why i used handle_unknown='ignore' in OneHotEncoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                       0\n",
       "codidiagingreso_716.66    0\n",
       "codidiagingreso_724.02    0\n",
       "codidiagingreso_724.01    0\n",
       "codidiagingreso_723.1     0\n",
       "                         ..\n",
       "codidiagingreso_410.61    0\n",
       "codidiagingreso_410.51    0\n",
       "codidiagingreso_410.41    0\n",
       "codidiagingreso_410.31    0\n",
       "codservicioreal_nan       0\n",
       "Length: 1944, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Implement a method to deal with missing values using simple techniques such as the imputation by\n",
    "# the mean or the median\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "imputer.fit(train)\n",
    "train_trans = imputer.transform(train)\n",
    "train_trans = pd.DataFrame(train_trans, columns=train.columns)\n",
    "train_trans.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                       0\n",
       "codidiagingreso_716.66    0\n",
       "codidiagingreso_724.02    0\n",
       "codidiagingreso_724.01    0\n",
       "codidiagingreso_723.1     0\n",
       "                         ..\n",
       "codidiagingreso_410.61    0\n",
       "codidiagingreso_410.51    0\n",
       "codidiagingreso_410.41    0\n",
       "codidiagingreso_410.31    0\n",
       "codservicioreal_nan       0\n",
       "Length: 1944, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ▪ The transformation applied on the training set of the data should be the same applied to the test set. \n",
    "test_trans = imputer.transform(test)\n",
    "test_trans = pd.DataFrame(test_trans, columns=test.columns)\n",
    "train_trans.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the method to deal with the missing values. Briefly explain the chosen alternative. What\n",
    "would happen if a variable without missing on the train set appears to have been missing in the test\n",
    "set? How would you deal with them?\n",
    "- removing entire rows that contain missing values \"train.dropna(inplace=True)\"\n",
    "- Fill missing values with the mean, median, or mode of the column. Mean is useful for continuous variables, while median is less sensitive to outliers. Mode is used for categorical variables.\n",
    "- Use more sophisticated imputation methods like K-Nearest Neighbors (KNN) or regression models to predict missing values based on other features\n",
    "- Introduce an additional binary feature indicating whether the value was missing. This way, the model can learn if missingness is informative.\n",
    "\n",
    "Handling Missing Values in Test Set:\n",
    "\n",
    "If a variable without missing values in the training set has missing values in the test set, it should be handle by using the same strategy that was applied to the training set:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we used the whole dataset to fit the imputer and the categorical variables’ method so we don’t have to worry about unconsidered values? Explain briefly why this is a terrible idea. \n",
    "\n",
    "Including the test set during preprocessing can lead to data leakage, where information from the test set is used to influence the preprocessing decisions. Its my lead to overly optimistic performance estimates. Whatsmore then its more difficult to check if your model is not overfited whats mean it has problem wih generalization and its unable to handle new values in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import the RandomForestClassifier and create the model with the default arguments\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38097, 1944), (7684,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trans.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [38097, 7684]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/igor/code/UPV/bds/week4/lab4.ipynb Komórka 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/igor/code/UPV/bds/week4/lab4.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# 2. Fit the model using the train set and the train labels\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/igor/code/UPV/bds/week4/lab4.ipynb#X40sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m rf\u001b[39m.\u001b[39;49mfit(train_trans, y_test)\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:345\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[1;32m    344\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 345\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    346\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.11/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [38097, 7684]"
     ]
    }
   ],
   "source": [
    "# 2. Fit the model using the train set and the train labels\n",
    "rf.fit(train_trans, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Get the probabilities for the positive class from the test set\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
